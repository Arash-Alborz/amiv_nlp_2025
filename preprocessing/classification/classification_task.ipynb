{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67a91217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved labeled trait data to /Users/arashalborz/Desktop/amiv_nlp_2025/processed_data/combined_author_embeddings_with_liwc_labeled.csv\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    ">>> Script for converting numbers to labels \n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "input_path = \"/Users/arashalborz/Desktop/amiv_nlp_2025/processed_data/combined_author_embeddings_with_liwc.csv\"\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "def score_to_label(score):\n",
    "    if score <= 32:\n",
    "        return \"Low\"\n",
    "    elif score <= 66:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"High\"\n",
    "\n",
    "traits = [\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]\n",
    "\n",
    "for trait in traits:\n",
    "    df[trait] = df[trait].apply(lambda x: score_to_label(x * 100))  # scale back to 0–100\n",
    "\n",
    "output_path = \"/Users/arashalborz/Desktop/amiv_nlp_2025/processed_data/combined_author_embeddings_with_liwc_labeled.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"✅ Saved labeled trait data to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dac2185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Openness - Accuracy: 0.4426751592356688\n",
      "SVM Openness - F1-score (macro): 0.3575830567902518\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        High       0.55      0.60      0.58       174\n",
      "         Low       0.22      0.21      0.22        48\n",
      "      Medium       0.31      0.26      0.28        92\n",
      "\n",
      "    accuracy                           0.44       314\n",
      "   macro avg       0.36      0.36      0.36       314\n",
      "weighted avg       0.43      0.44      0.43       314\n",
      "\n",
      "✅ Saved to svm_classification_report_openness.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(\"/Users/arashalborz/Desktop/amiv_nlp_2025/processed_data/combined_author_embeddings_with_liwc_labeled.csv\")\n",
    "\n",
    "# --- Prepare input (X) and label (y: only openness) ---\n",
    "X = df[[col for col in df.columns if col.startswith(\"embed_\") or col.startswith(\"liwc_\")]].values\n",
    "y = df[\"openness\"].values  # Categorical label: Low, Medium, High\n",
    "\n",
    "# --- Split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Normalize features ---\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --- Train SVM ---\n",
    "svm = SVC(kernel=\"linear\", C=1.0, random_state=42)\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# --- Predict ---\n",
    "y_pred = svm.predict(X_test_scaled)\n",
    "\n",
    "# --- Evaluation ---\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "report = classification_report(y_test, y_pred, zero_division=0)\n",
    "\n",
    "print(\"SVM Openness - Accuracy:\", accuracy)\n",
    "print(\"SVM Openness - F1-score (macro):\", f1)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Save report to file\n",
    "with open(\"svm_classification_report_openness.txt\", \"w\") as f:\n",
    "    f.write(\"SVM Classification Report for Openness:\\n\")\n",
    "    f.write(report)\n",
    "\n",
    "print(\"✅ Saved to svm_classification_report_openness.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5054c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Trait: Openness ====\n",
      "Accuracy: 0.4426751592356688\n",
      "F1-score (macro): 0.3575830567902518\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        High       0.55      0.60      0.58       174\n",
      "         Low       0.22      0.21      0.22        48\n",
      "      Medium       0.31      0.26      0.28        92\n",
      "\n",
      "    accuracy                           0.44       314\n",
      "   macro avg       0.36      0.36      0.36       314\n",
      "weighted avg       0.43      0.44      0.43       314\n",
      "\n",
      "\n",
      "==== Trait: Conscientiousness ====\n",
      "Accuracy: 0.4267515923566879\n",
      "F1-score (macro): 0.4098462519212225\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        High       0.35      0.47      0.40        85\n",
      "         Low       0.52      0.47      0.50       146\n",
      "      Medium       0.37      0.30      0.33        83\n",
      "\n",
      "    accuracy                           0.43       314\n",
      "   macro avg       0.41      0.41      0.41       314\n",
      "weighted avg       0.44      0.43      0.43       314\n",
      "\n",
      "\n",
      "==== Trait: Extraversion ====\n",
      "Accuracy: 0.4840764331210191\n",
      "F1-score (macro): 0.4415439912486326\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        High       0.31      0.40      0.35        65\n",
      "         Low       0.65      0.57      0.61       169\n",
      "      Medium       0.37      0.38      0.37        80\n",
      "\n",
      "    accuracy                           0.48       314\n",
      "   macro avg       0.44      0.45      0.44       314\n",
      "weighted avg       0.51      0.48      0.49       314\n",
      "\n",
      "\n",
      "==== Trait: Agreeableness ====\n",
      "Accuracy: 0.3853503184713376\n",
      "F1-score (macro): 0.36094941808577136\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        High       0.36      0.37      0.37        94\n",
      "         Low       0.49      0.50      0.49       137\n",
      "      Medium       0.23      0.22      0.22        83\n",
      "\n",
      "    accuracy                           0.39       314\n",
      "   macro avg       0.36      0.36      0.36       314\n",
      "weighted avg       0.38      0.39      0.38       314\n",
      "\n",
      "\n",
      "==== Trait: Neuroticism ====\n",
      "Accuracy: 0.4140127388535032\n",
      "F1-score (macro): 0.396973945485271\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        High       0.49      0.58      0.53       113\n",
      "         Low       0.42      0.37      0.40       115\n",
      "      Medium       0.28      0.26      0.27        86\n",
      "\n",
      "    accuracy                           0.41       314\n",
      "   macro avg       0.40      0.40      0.40       314\n",
      "weighted avg       0.41      0.41      0.41       314\n",
      "\n",
      "\n",
      "✅ All SVM classification reports saved to svm_classification_report_all_traits.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Load the labeled data\n",
    "df = pd.read_csv(\"combined_author_embeddings_with_liwc_labeled.csv\")\n",
    "\n",
    "# Prepare feature matrix X\n",
    "X = df[[col for col in df.columns if col.startswith(\"embed_\") or col.startswith(\"liwc_\")]].values\n",
    "\n",
    "# Trait columns\n",
    "traits = [\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]\n",
    "\n",
    "# Store results\n",
    "reports = []\n",
    "\n",
    "# Loop over each trait\n",
    "for trait in traits:\n",
    "    print(f\"\\n==== Trait: {trait.capitalize()} ====\")\n",
    "\n",
    "    # Labels\n",
    "    y = df[trait].values\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Train SVM\n",
    "    svm = SVC(kernel=\"linear\", C=1.0, random_state=42)\n",
    "    svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = svm.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    report = classification_report(y_test, y_pred, zero_division=0)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1-score (macro):\", f1)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "\n",
    "    # Save each report\n",
    "    reports.append((trait, accuracy, f1, report))\n",
    "\n",
    "# Save all reports to file\n",
    "with open(\"svm_classification_report_all_traits.txt\", \"w\") as f:\n",
    "    for trait, acc, f1, rep in reports:\n",
    "        f.write(f\"=== Trait: {trait.capitalize()} ===\\n\")\n",
    "        f.write(f\"Accuracy: {acc:.4f}\\n\")\n",
    "        f.write(f\"F1-score (macro): {f1:.4f}\\n\")\n",
    "        f.write(rep + \"\\n\\n\")\n",
    "\n",
    "print(\"\\n✅ All SVM classification reports saved to svm_classification_report_all_traits.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2fedbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Openness - Accuracy: 0.5127388535031847\n",
      "Openness - F1-score (macro): 0.2937782654459396\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        High       0.56      0.86      0.67       174\n",
      "         Low       0.09      0.02      0.03        48\n",
      "      Medium       0.31      0.12      0.17        92\n",
      "\n",
      "    accuracy                           0.51       314\n",
      "   macro avg       0.32      0.33      0.29       314\n",
      "weighted avg       0.41      0.51      0.43       314\n",
      "\n",
      "✅ Saved report to random_forest_openness_report.txt\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "RANDOM FOREST\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Load the labeled data\n",
    "df = pd.read_csv(\"combined_author_embeddings_with_liwc_labeled.csv\")\n",
    "\n",
    "# Prepare feature matrix X (all LIWC + BERT embeddings)\n",
    "X = df[[col for col in df.columns if col.startswith(\"embed_\") or col.startswith(\"liwc_\")]].values\n",
    "\n",
    "# Target labels (Openness)\n",
    "y = df[\"openness\"].values  # Should be \"Low\", \"Medium\", or \"High\"\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = rf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "report = classification_report(y_test, y_pred, zero_division=0)\n",
    "\n",
    "# Print results\n",
    "print(\"Openness - Accuracy:\", accuracy)\n",
    "print(\"Openness - F1-score (macro):\", f1)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Save report\n",
    "with open(\"random_forest_openness_report.txt\", \"w\") as f:\n",
    "    f.write(\"Classification Report - Random Forest (Openness):\\n\")\n",
    "    f.write(report)\n",
    "\n",
    "print(\"✅ Saved report to random_forest_openness_report.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05b035b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Predicting Openness ==========\n",
      "Accuracy: 0.5127\n",
      "F1-score (macro): 0.2938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.56      0.86      0.67       174\n",
      "         Low       0.09      0.02      0.03        48\n",
      "      Medium       0.31      0.12      0.17        92\n",
      "\n",
      "    accuracy                           0.51       314\n",
      "   macro avg       0.32      0.33      0.29       314\n",
      "weighted avg       0.41      0.51      0.43       314\n",
      "\n",
      "\n",
      "========== Predicting Conscientiousness ==========\n",
      "Accuracy: 0.4427\n",
      "F1-score (macro): 0.2882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.40      0.07      0.12        85\n",
      "         Low       0.47      0.86      0.61       146\n",
      "      Medium       0.24      0.10      0.14        83\n",
      "\n",
      "    accuracy                           0.44       314\n",
      "   macro avg       0.37      0.34      0.29       314\n",
      "weighted avg       0.39      0.44      0.35       314\n",
      "\n",
      "\n",
      "========== Predicting Extraversion ==========\n",
      "Accuracy: 0.5318\n",
      "F1-score (macro): 0.3124\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.27      0.06      0.10        65\n",
      "         Low       0.57      0.92      0.70       169\n",
      "      Medium       0.29      0.09      0.13        80\n",
      "\n",
      "    accuracy                           0.53       314\n",
      "   macro avg       0.38      0.36      0.31       314\n",
      "weighted avg       0.43      0.53      0.43       314\n",
      "\n",
      "\n",
      "========== Predicting Agreeableness ==========\n",
      "Accuracy: 0.4395\n",
      "F1-score (macro): 0.3338\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.35      0.20      0.26        94\n",
      "         Low       0.47      0.81      0.60       137\n",
      "      Medium       0.33      0.10      0.15        83\n",
      "\n",
      "    accuracy                           0.44       314\n",
      "   macro avg       0.38      0.37      0.33       314\n",
      "weighted avg       0.40      0.44      0.38       314\n",
      "\n",
      "\n",
      "========== Predicting Neuroticism ==========\n",
      "Accuracy: 0.3885\n",
      "F1-score (macro): 0.3294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.39      0.60      0.47       113\n",
      "         Low       0.42      0.43      0.42       115\n",
      "      Medium       0.22      0.06      0.09        86\n",
      "\n",
      "    accuracy                           0.39       314\n",
      "   macro avg       0.34      0.36      0.33       314\n",
      "weighted avg       0.35      0.39      0.35       314\n",
      "\n",
      "\n",
      "✅ Saved full trait classification report to random_forest_all_traits_report.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Load the labeled dataset\n",
    "df = pd.read_csv(\"combined_author_embeddings_with_liwc_labeled.csv\")\n",
    "\n",
    "# Input features\n",
    "X = df[[col for col in df.columns if col.startswith(\"embed_\") or col.startswith(\"liwc_\")]].values\n",
    "\n",
    "# Define traits to classify\n",
    "traits = [\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Store evaluation results\n",
    "all_reports = \"\"\n",
    "\n",
    "for trait in traits:\n",
    "    print(f\"\\n========== Predicting {trait.capitalize()} ==========\")\n",
    "    \n",
    "    # Labels\n",
    "    y = df[trait].values\n",
    "    \n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train model\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    report = classification_report(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "    # Output\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1-score (macro): {f1:.4f}\")\n",
    "    print(report)\n",
    "    \n",
    "    all_reports += f\"\\n\\n=== {trait.upper()} ===\\n\"\n",
    "    all_reports += f\"Accuracy: {acc:.4f}\\nF1-score (macro): {f1:.4f}\\n\"\n",
    "    all_reports += report\n",
    "\n",
    "# Save all reports to file\n",
    "with open(\"random_forest_all_traits_report.txt\", \"w\") as f:\n",
    "    f.write(\"Classification Reports - Random Forest (All Traits)\\n\")\n",
    "    f.write(all_reports)\n",
    "\n",
    "print(\"\\n✅ Saved full trait classification report to random_forest_all_traits_report.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amiv_nlp_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
