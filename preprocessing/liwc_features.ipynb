{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366911b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Extract LIWC features from filtered_pandora_all_labeled.json\n",
    "Each author → concatenate all comments → get normalized LIWC category vector\n",
    "Also saves Big Five traits and author ID\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "def load_liwc_dic(dic_path):\n",
    "    category_map = defaultdict(list)\n",
    "    with open(dic_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if ':' not in line:\n",
    "                continue\n",
    "            parts = line.strip().split()\n",
    "            category = parts[0].rstrip(':')\n",
    "            words = parts[1:]\n",
    "            category_map[category] = words\n",
    "    return category_map\n",
    "\n",
    "\n",
    "def liwc_embedding(text, category_map):\n",
    "    tokens = re.findall(r\"\\b\\w+\\b\", text.lower()) # tokens = text.lower().split()\n",
    "    counts = Counter()\n",
    "    for category, words in category_map.items():\n",
    "        for token in tokens:\n",
    "            if token in words:\n",
    "                counts[category] += 1\n",
    "    sorted_categories = sorted(category_map.keys())\n",
    "    vec = np.array([counts.get(cat, 0) for cat in sorted_categories])\n",
    "    return vec\n",
    "\n",
    "liwc_dic_path = \"output.dic\" \n",
    "input_filename = \"filtered_pandora_all_labeled.json\"\n",
    "input_folder = os.path.dirname(\"/Users/arashalborz/Desktop/Data/filtered_pandora_all_labeled.json\") \n",
    "input_path = os.path.join(input_folder, input_filename)\n",
    "save_path = os.path.join(input_folder, \"liwc_author_data.csv\")\n",
    "\n",
    "category_map = load_liwc_dic(liwc_dic_path)\n",
    "sorted_categories = sorted(category_map.keys())\n",
    "\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "rows = []\n",
    "\n",
    "for author in data[\"authors\"]:\n",
    "    author_id = author[\"id\"]\n",
    "    comments = author.get(\"comments\", [])\n",
    "    full_text = \" \".join(comments)\n",
    "\n",
    "    vec = liwc_embedding(full_text, category_map)\n",
    "    if np.sum(vec) > 0:\n",
    "        vec = vec / np.sum(vec)  # normalize vector to sum to 1\n",
    "\n",
    "    traits = author[\"labels\"]\n",
    "\n",
    "    row = {\n",
    "        \"id\": author_id,\n",
    "        \"Openness\": traits[\"Openness\"],\n",
    "        \"Conscientiousness\": traits[\"Conscientiousness\"],\n",
    "        \"Extraversion\": traits[\"Extraversion\"],\n",
    "        \"Agreeableness\": traits[\"Agreeableness\"],\n",
    "        \"Emotional stability\": traits[\"Emotional stability\"]\n",
    "    }\n",
    "\n",
    "    for i, cat in enumerate(sorted_categories):\n",
    "        row[f\"liwc_{cat}\"] = vec[i]\n",
    "\n",
    "    rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(save_path, index=False)\n",
    "print(f\"LIWC features saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2586b27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Extract LIWC features from val_data.csv\n",
    "Each row → concatenate Q1, Q2, Q3 → get normalized LIWC vector + labels\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "def load_liwc_dic(dic_path):\n",
    "    category_map = defaultdict(list)\n",
    "    with open(dic_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if ':' not in line:\n",
    "                continue\n",
    "            parts = line.strip().split()\n",
    "            category = parts[0].rstrip(':')\n",
    "            words = parts[1:]\n",
    "            category_map[category] = words\n",
    "    return category_map\n",
    "\n",
    "def liwc_embedding(text, category_map):\n",
    "    tokens = re.findall(r\"\\b\\w+\\b\", text.lower()) # tokens = text.lower().split()\n",
    "    counts = Counter()\n",
    "    for category, words in category_map.items():\n",
    "        for token in tokens:\n",
    "            if token in words:\n",
    "                counts[category] += 1\n",
    "    sorted_categories = sorted(category_map.keys())\n",
    "    vec = np.array([counts.get(cat, 0) for cat in sorted_categories])\n",
    "    return vec\n",
    "\n",
    "liwc_dic_path = \"output.dic\"\n",
    "val_csv_path = \"/Users/arashalborz/Desktop/Data/val_data.csv\"\n",
    "save_path = \"/Users/arashalborz/Desktop/Data/liwc_val_data.csv\"\n",
    "\n",
    "category_map = load_liwc_dic(liwc_dic_path)\n",
    "sorted_categories = sorted(category_map.keys())\n",
    "val_df = pd.read_csv(val_csv_path)\n",
    "\n",
    "# traits\n",
    "trait_columns = [\"Openness\", \"Conscientiousness\", \"Extraversion\", \"Agreeableness\", \"Emotional stability\"]\n",
    "\n",
    "rows = []\n",
    "\n",
    "for idx, row in val_df.iterrows():\n",
    "    author_id = str(row[\"id\"])\n",
    "    text = \" \".join(str(row[q]) for q in ['Q1', 'Q2', 'Q3'] if pd.notna(row[q]))\n",
    "\n",
    "    vec = liwc_embedding(text, category_map)\n",
    "    if np.sum(vec) > 0:\n",
    "        vec = vec / np.sum(vec)\n",
    "\n",
    "    row_data = {\n",
    "        \"id\": author_id,\n",
    "        **{trait: row[trait] for trait in trait_columns}\n",
    "    }\n",
    "\n",
    "    for i, cat in enumerate(sorted_categories):\n",
    "        row_data[f\"liwc_{cat}\"] = vec[i]\n",
    "\n",
    "    rows.append(row_data)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(save_path, index=False)\n",
    "print(f\"LIWC features + labels saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a4cada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "val_path = \"/Users/arashalborz/Desktop/amiv_nlp_2025/processed_data/val_embeddings_with_liwc_labeled.csv\"\n",
    "\n",
    "df = pd.read_csv(val_path, sep=\";\")\n",
    "\n",
    "# 1:\n",
    "df = df.applymap(lambda x: str(x).replace(\",\", \".\") if isinstance(x, str) else x)\n",
    "\n",
    "# 2:\n",
    "for col in df.columns:\n",
    "    try:\n",
    "        df[col] = pd.to_numeric(df[col])\n",
    "    except ValueError:\n",
    "        pass  # skip non-numeric columns\n",
    "\n",
    "df.to_csv(val_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d16f345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_path = \"/Users/arashalborz/Desktop/amiv_nlp_2025/processed_data/combined_author_embeddings_with_liwc_labeled.csv\"\n",
    "val_path = \"/Users/arashalborz/Desktop/amiv_nlp_2025/processed_data/val_embeddings_with_liwc_labeled.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "val_df = pd.read_csv(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be8e30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = set(train_df.columns)\n",
    "val_cols = set(val_df.columns)\n",
    "\n",
    "print(\"In train but not in val:\", train_cols - val_cols)\n",
    "print(\"In val but not in train:\", val_cols - train_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d75c659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "val_path = \"/Users/arashalborz/Desktop/amiv_nlp_2025/processed_data/val_embeddings_with_liwc_labeled.csv\"\n",
    "val_df = pd.read_csv(val_path)\n",
    "\n",
    "# unnecessary columns drop\n",
    "columns_to_drop = ['q1', 'q2', 'q3', 'full_text', 'humility']\n",
    "val_df = val_df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "val_df.to_csv(val_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82b7b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "val_path = \"/Users/arashalborz/Desktop/amiv_nlp_2025/processed_data/val_embeddings_with_liwc_labeled.csv\"\n",
    "val_df = pd.read_csv(val_path)\n",
    "\n",
    "val_df[\"id\"] = val_df[\"id\"].astype(str)\n",
    "\n",
    "columns_to_drop = [\"q1\", \"q2\", \"q3\", \"humility\", \"full_text\"]\n",
    "val_df = val_df.drop(columns=[col for col in columns_to_drop if col in val_df.columns])\n",
    "\n",
    "val_df.to_csv(val_path, index=False)\n",
    "\n",
    "print(\"Validation set cleaned and saved:\", val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc595cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    ">>> Script for merginf liwc features with embeddings\n",
    "\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# for validation set\n",
    "embedding_csv = \"../processed_data/validation/val_embeddings.csv\"\n",
    "liwc_csv = \"../processed_data/validation/liwc_val_with_regex.csv\"\n",
    "output_csv = \"../processed_data/validation/comb_val_liwc_embed.csv\"\n",
    "\n",
    "# for train set\n",
    "#embedding_csv = \"../processed_data/train/author_embeddings.csv\"\n",
    "#liwc_csv = \"../processed_data/train/liwc_train_with_regex.csv\"\n",
    "#output_csv = \"../processed_data/train/comb_train_liwc_embed.csv\"\n",
    "\n",
    "emb_df = pd.read_csv(embedding_csv)\n",
    "liwc_df = pd.read_csv(liwc_csv)\n",
    "\n",
    "trait_columns = [\"Openness\", \"Conscientiousness\", \"Extraversion\", \"Agreeableness\", \"Emotional stability\"]\n",
    "emb_df = emb_df.drop(columns=[col for col in trait_columns if col in emb_df.columns], errors=\"ignore\")\n",
    "\n",
    "merged_df = pd.merge(liwc_df, emb_df, on=\"id\", how=\"inner\")\n",
    "\n",
    "merged_df.to_csv(output_csv, index=False)\n",
    "print(f\"Merged file saved to: {output_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amiv_nlp_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
