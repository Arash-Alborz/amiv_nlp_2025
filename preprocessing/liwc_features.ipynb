{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366911b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIWC features saved to /Users/arashalborz/Desktop/Data/liwc_author_data.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Extract LIWC features from filtered_pandora_all_labeled.json\n",
    "Each author → concatenate all comments → get normalized LIWC category vector\n",
    "Also saves Big Five traits and author ID\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "def load_liwc_dic(dic_path):\n",
    "    category_map = defaultdict(list)\n",
    "    with open(dic_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if ':' not in line:\n",
    "                continue\n",
    "            parts = line.strip().split()\n",
    "            category = parts[0].rstrip(':')\n",
    "            words = parts[1:]\n",
    "            category_map[category] = words\n",
    "    return category_map\n",
    "\n",
    "\n",
    "def liwc_embedding(text, category_map):\n",
    "    tokens = re.findall(r\"\\b\\w+\\b\", text.lower()) # tokens = text.lower().split()\n",
    "    counts = Counter()\n",
    "    for category, words in category_map.items():\n",
    "        for token in tokens:\n",
    "            if token in words:\n",
    "                counts[category] += 1\n",
    "    sorted_categories = sorted(category_map.keys())\n",
    "    vec = np.array([counts.get(cat, 0) for cat in sorted_categories])\n",
    "    return vec\n",
    "\n",
    "liwc_dic_path = \"output.dic\" \n",
    "input_filename = \"filtered_pandora_all_labeled.json\"\n",
    "input_folder = os.path.dirname(\"/Users/arashalborz/Desktop/Data/filtered_pandora_all_labeled.json\") \n",
    "input_path = os.path.join(input_folder, input_filename)\n",
    "save_path = os.path.join(input_folder, \"liwc_author_data.csv\")\n",
    "\n",
    "category_map = load_liwc_dic(liwc_dic_path)\n",
    "sorted_categories = sorted(category_map.keys())\n",
    "\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "rows = []\n",
    "\n",
    "for author in data[\"authors\"]:\n",
    "    author_id = author[\"id\"]\n",
    "    comments = author.get(\"comments\", [])\n",
    "    full_text = \" \".join(comments)\n",
    "\n",
    "    vec = liwc_embedding(full_text, category_map)\n",
    "    if np.sum(vec) > 0:\n",
    "        vec = vec / np.sum(vec)  # normalize vector to sum to 1\n",
    "\n",
    "    traits = author[\"labels\"]\n",
    "\n",
    "    row = {\n",
    "        \"id\": author_id,\n",
    "        \"Openness\": traits[\"Openness\"],\n",
    "        \"Conscientiousness\": traits[\"Conscientiousness\"],\n",
    "        \"Extraversion\": traits[\"Extraversion\"],\n",
    "        \"Agreeableness\": traits[\"Agreeableness\"],\n",
    "        \"Emotional stability\": traits[\"Emotional stability\"]\n",
    "    }\n",
    "\n",
    "    for i, cat in enumerate(sorted_categories):\n",
    "        row[f\"liwc_{cat}\"] = vec[i]\n",
    "\n",
    "    rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(save_path, index=False)\n",
    "print(f\"LIWC features saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2586b27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LIWC features + labels saved to /Users/arashalborz/Desktop/Data/liwc_val_data.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Extract LIWC features from val_data.csv\n",
    "Each row → concatenate Q1, Q2, Q3 → get normalized LIWC vector + labels\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "def load_liwc_dic(dic_path):\n",
    "    category_map = defaultdict(list)\n",
    "    with open(dic_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if ':' not in line:\n",
    "                continue\n",
    "            parts = line.strip().split()\n",
    "            category = parts[0].rstrip(':')\n",
    "            words = parts[1:]\n",
    "            category_map[category] = words\n",
    "    return category_map\n",
    "\n",
    "def liwc_embedding(text, category_map):\n",
    "    tokens = re.findall(r\"\\b\\w+\\b\", text.lower()) # tokens = text.lower().split()\n",
    "    counts = Counter()\n",
    "    for category, words in category_map.items():\n",
    "        for token in tokens:\n",
    "            if token in words:\n",
    "                counts[category] += 1\n",
    "    sorted_categories = sorted(category_map.keys())\n",
    "    vec = np.array([counts.get(cat, 0) for cat in sorted_categories])\n",
    "    return vec\n",
    "\n",
    "# === Paths ===\n",
    "liwc_dic_path = \"output.dic\"\n",
    "val_csv_path = \"/Users/arashalborz/Desktop/Data/val_data.csv\"\n",
    "save_path = \"/Users/arashalborz/Desktop/Data/liwc_val_data.csv\"\n",
    "\n",
    "# === Load dictionary and CSV ===\n",
    "category_map = load_liwc_dic(liwc_dic_path)\n",
    "sorted_categories = sorted(category_map.keys())\n",
    "val_df = pd.read_csv(val_csv_path)\n",
    "\n",
    "# === Personality trait columns ===\n",
    "trait_columns = [\"Openness\", \"Conscientiousness\", \"Extraversion\", \"Agreeableness\", \"Emotional stability\"]\n",
    "\n",
    "rows = []\n",
    "\n",
    "for idx, row in val_df.iterrows():\n",
    "    author_id = str(row[\"id\"])\n",
    "    text = \" \".join(str(row[q]) for q in ['Q1', 'Q2', 'Q3'] if pd.notna(row[q]))\n",
    "\n",
    "    vec = liwc_embedding(text, category_map)\n",
    "    if np.sum(vec) > 0:\n",
    "        vec = vec / np.sum(vec)\n",
    "\n",
    "    row_data = {\n",
    "        \"id\": author_id,\n",
    "        **{trait: row[trait] for trait in trait_columns}\n",
    "    }\n",
    "\n",
    "    for i, cat in enumerate(sorted_categories):\n",
    "        row_data[f\"liwc_{cat}\"] = vec[i]\n",
    "\n",
    "    rows.append(row_data)\n",
    "\n",
    "# === Save to CSV ===\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(save_path, index=False)\n",
    "print(f\"✅ LIWC features + labels saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a4cada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned and saved file: /Users/arashalborz/Desktop/amiv_nlp_2025/processed_data/val_embeddings_with_liwc_labeled.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/18/rg5htfh543ddx8vy8gstpvwm0000gn/T/ipykernel_28667/3473199985.py:10: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).replace(\",\", \".\") if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your file\n",
    "val_path = \"/Users/arashalborz/Desktop/amiv_nlp_2025/processed_data/val_embeddings_with_liwc_labeled.csv\"\n",
    "\n",
    "# Step 1: Load with correct separator\n",
    "df = pd.read_csv(val_path, sep=\";\")\n",
    "\n",
    "# Step 2: Replace comma with dot in all string cells\n",
    "df = df.applymap(lambda x: str(x).replace(\",\", \".\") if isinstance(x, str) else x)\n",
    "\n",
    "# Step 3: Convert numeric columns to float where possible\n",
    "for col in df.columns:\n",
    "    try:\n",
    "        df[col] = pd.to_numeric(df[col])\n",
    "    except ValueError:\n",
    "        pass  # skip non-numeric columns\n",
    "\n",
    "df.to_csv(val_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d16f345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_path = \"/Users/arashalborz/Desktop/amiv_nlp_2025/processed_data/combined_author_embeddings_with_liwc_labeled.csv\"\n",
    "val_path = \"/Users/arashalborz/Desktop/amiv_nlp_2025/processed_data/val_embeddings_with_liwc_labeled.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "val_df = pd.read_csv(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5be8e30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In train but not in val: set()\n",
      "In val but not in train: {'humility', 'full_text', 'q3', 'q2', 'q1'}\n"
     ]
    }
   ],
   "source": [
    "train_cols = set(train_df.columns)\n",
    "val_cols = set(val_df.columns)\n",
    "\n",
    "print(\"In train but not in val:\", train_cols - val_cols)\n",
    "print(\"In val but not in train:\", val_cols - train_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d75c659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extra columns dropped and validation file updated.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load validation file\n",
    "val_path = \"/Users/arashalborz/Desktop/amiv_nlp_2025/processed_data/val_embeddings_with_liwc_labeled.csv\"\n",
    "val_df = pd.read_csv(val_path)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_drop = ['q1', 'q2', 'q3', 'full_text', 'humility']\n",
    "val_df = val_df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# Save the cleaned file (overwrite original)\n",
    "val_df.to_csv(val_path, index=False)\n",
    "print(\"✅ Extra columns dropped and validation file updated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c04042a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dtypes:\n",
      " id                    object\n",
      "embed_0              float64\n",
      "embed_1              float64\n",
      "embed_2              float64\n",
      "embed_3              float64\n",
      "                      ...   \n",
      "openness              object\n",
      "conscientiousness     object\n",
      "extraversion          object\n",
      "agreeableness         object\n",
      "neuroticism           object\n",
      "Length: 838, dtype: object\n",
      "\n",
      "Val dtypes:\n",
      " id                     int64\n",
      "openness              object\n",
      "conscientiousness     object\n",
      "extraversion          object\n",
      "agreeableness         object\n",
      "                      ...   \n",
      "liwc_Time            float64\n",
      "liwc_Verbs           float64\n",
      "liwc_We              float64\n",
      "liwc_Work            float64\n",
      "liwc_You             float64\n",
      "Length: 838, dtype: object\n",
      "\n",
      "Sample row from train:\n",
      " id                   -Areopagan-\n",
      "embed_0                   0.9595\n",
      "embed_1                  -0.4644\n",
      "embed_2                    1.148\n",
      "embed_3                  -0.4001\n",
      "                        ...     \n",
      "openness                    High\n",
      "conscientiousness           High\n",
      "extraversion              Medium\n",
      "agreeableness                Low\n",
      "neuroticism                  Low\n",
      "Name: 0, Length: 838, dtype: object\n",
      "\n",
      "Sample row from val:\n",
      " id                          1\n",
      "openness                 High\n",
      "conscientiousness         Low\n",
      "extraversion             High\n",
      "agreeableness            High\n",
      "                       ...   \n",
      "liwc_Time            0.012579\n",
      "liwc_Verbs           0.058401\n",
      "liwc_We              0.002695\n",
      "liwc_Work            0.002695\n",
      "liwc_You             0.001797\n",
      "Name: 0, Length: 838, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dtypes:\\n\", train_df.dtypes)\n",
    "print(\"\\nVal dtypes:\\n\", val_df.dtypes)\n",
    "\n",
    "# Optional: check sample row\n",
    "print(\"\\nSample row from train:\\n\", train_df.iloc[0])\n",
    "print(\"\\nSample row from val:\\n\", val_df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a82b7b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Validation set cleaned and saved: /Users/arashalborz/Desktop/amiv_nlp_2025/processed_data/val_embeddings_with_liwc_labeled.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the original validation CSV\n",
    "val_path = \"/Users/arashalborz/Desktop/amiv_nlp_2025/processed_data/val_embeddings_with_liwc_labeled.csv\"\n",
    "val_df = pd.read_csv(val_path)\n",
    "\n",
    "# Convert 'id' to string for consistency\n",
    "val_df[\"id\"] = val_df[\"id\"].astype(str)\n",
    "\n",
    "# Drop unwanted columns if they exist\n",
    "columns_to_drop = [\"q1\", \"q2\", \"q3\", \"humility\", \"full_text\"]\n",
    "val_df = val_df.drop(columns=[col for col in columns_to_drop if col in val_df.columns])\n",
    "\n",
    "# Save cleaned DataFrame (overwrite)\n",
    "val_df.to_csv(val_path, index=False)\n",
    "\n",
    "print(\"✅ Validation set cleaned and saved:\", val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc595cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged file saved to: ../processed_data/validation/comb_val_liwc_embed.csv\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    ">>> Script for merginf liwc features with embeddings\n",
    "\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# for validation set\n",
    "embedding_csv = \"../processed_data/validation/val_embeddings.csv\"\n",
    "liwc_csv = \"../processed_data/validation/liwc_val_with_regex.csv\"\n",
    "output_csv = \"../processed_data/validation/comb_val_liwc_embed.csv\"\n",
    "\n",
    "# for train set\n",
    "#embedding_csv = \"../processed_data/train/author_embeddings.csv\"\n",
    "#liwc_csv = \"../processed_data/train/liwc_train_with_regex.csv\"\n",
    "#output_csv = \"../processed_data/train/comb_train_liwc_embed.csv\"\n",
    "\n",
    "emb_df = pd.read_csv(embedding_csv)\n",
    "liwc_df = pd.read_csv(liwc_csv)\n",
    "\n",
    "trait_columns = [\"Openness\", \"Conscientiousness\", \"Extraversion\", \"Agreeableness\", \"Emotional stability\"]\n",
    "emb_df = emb_df.drop(columns=[col for col in trait_columns if col in emb_df.columns], errors=\"ignore\")\n",
    "\n",
    "merged_df = pd.merge(liwc_df, emb_df, on=\"id\", how=\"inner\")\n",
    "\n",
    "merged_df.to_csv(output_csv, index=False)\n",
    "print(f\"Merged file saved to: {output_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amiv_nlp_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
