{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa4cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    ">>> Script for generating synthetic data replicating job interview texts\n",
    "IMPORTANT: This script gets the API-key from the environment. \n",
    ">>> Please set your API-key as environment variable.\n",
    ">>> The script also generates number of input and output token.\n",
    "\n",
    "'''\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import tiktoken\n",
    "from datetime import datetime\n",
    "\n",
    "client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "val_df = pd.read_csv(\"../val_data.csv\")\n",
    "example1 = val_df.iloc[0]\n",
    "example2 = val_df.iloc[1]\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are generating synthetic job interview responses to the following 3 questions:\n",
    "\n",
    "Q1. Please describe a situation where you were presented with a problem outside of your comfort zone and where you were able to come up with a creative solution.\n",
    "Q2. Tell us about a time when you have failed or made a mistake. What happened? What did you learn from this experience?\n",
    "Q3. Describe a situation in which you got a group of people to work together as a team. Did you encounter any issues? What was the end result?\n",
    "\n",
    "Here are two examples of answers to these questions:\n",
    "\n",
    "Example 1:\n",
    "Q1,\"{example1['Q1']}\"\n",
    "Q2,\"{example1['Q2']}\"\n",
    "Q3,\"{example1['Q3']}\"\n",
    "\n",
    "Example 2:\n",
    "Q1,\"{example2['Q1']}\"\n",
    "Q2,\"{example2['Q2']}\"\n",
    "Q3,\"{example2['Q3']}\"\n",
    "\n",
    "Now generate a new set of answers in the same CSV format:\n",
    "Q1,\"...\"\n",
    "Q2,\"...\"\n",
    "Q3,\"...\"\n",
    "\"\"\"\n",
    "\n",
    "NUM_SYNTHETIC_SAMPLES = 35\n",
    "synthetic_rows = []\n",
    "token_stats = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(NUM_SYNTHETIC_SAMPLES):\n",
    "    print(f\"Generating sample {i+1}/{NUM_SYNTHETIC_SAMPLES}...\")\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.8,\n",
    "        )\n",
    "        content = response.choices[0].message.content\n",
    "\n",
    "        input_tokens = len(enc.encode(prompt))\n",
    "        output_tokens = len(enc.encode(content))\n",
    "        token_stats.append({\"input_tokens\": input_tokens, \"output_tokens\": output_tokens})\n",
    "\n",
    "        lines = content.strip().splitlines()\n",
    "        q1 = lines[0].split(\",\", 1)[1].strip().strip('\"')\n",
    "        q2 = lines[1].split(\",\", 1)[1].strip().strip('\"')\n",
    "        q3 = lines[2].split(\",\", 1)[1].strip().strip('\"')\n",
    "        synthetic_rows.append({\"Q1\": q1, \"Q2\": q2, \"Q3\": q3})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    time.sleep(1.2)\n",
    "\n",
    "output_df = pd.DataFrame(synthetic_rows)\n",
    "output_df.to_csv(\"synthetic_val_data.csv\", index=True)\n",
    "\n",
    "token_df = pd.DataFrame(token_stats)\n",
    "token_df.to_csv(\"synthetic_val_token_usage.csv\", index=True)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed = end_time - start_time\n",
    "total_input = sum(row[\"input_tokens\"] for row in token_stats)\n",
    "total_output = sum(row[\"output_tokens\"] for row in token_stats)\n",
    "\n",
    "print(\"Saved to synthetic_val_data.csv\")\n",
    "print(\"Token usage saved to synthetic_val_token_usage.csv\")\n",
    "print(f\"Total time: {elapsed:.2f} seconds\")\n",
    "print(f\"Total input tokens: {total_input}\")\n",
    "print(f\"Total output tokens: {total_output}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amiv_nlp_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
