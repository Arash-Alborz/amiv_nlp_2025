{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75db7479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Generating sample 1/5...\n",
      "ðŸ”„ Generating sample 2/5...\n",
      "ðŸ”„ Generating sample 3/5...\n",
      "ðŸ”„ Generating sample 4/5...\n",
      "ðŸ”„ Generating sample 5/5...\n",
      "âœ… Saved to synthetic_val_data.csv\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "client = openai.OpenAI(api_key=\"...\")\n",
    "\n",
    "# loading examples\n",
    "val_df = pd.read_csv(\"/Users/arashalborz/Desktop/Data/val_data.csv\")\n",
    "example1 = val_df.iloc[0]\n",
    "example2 = val_df.iloc[1]\n",
    "\n",
    "# Interview questions + prompt with real examples\n",
    "prompt = f\"\"\"\n",
    "You are generating synthetic job interview responses to the following 3 questions:\n",
    "\n",
    "Q1. Please describe a situation where you were presented with a problem outside of your comfort zone and where you were able to come up with a creative solution.\n",
    "Q2. Tell us about a time when you have failed or made a mistake. What happened? What did you learn from this experience?\n",
    "Q3. Describe a situation in which you got a group of people to work together as a team. Did you encounter any issues? What was the end result?\n",
    "\n",
    "Here are two examples:\n",
    "\n",
    "Example 1:\n",
    "Q1,\"{example1['Q1']}\"\n",
    "Q2,\"{example1['Q2']}\"\n",
    "Q3,\"{example1['Q3']}\"\n",
    "\n",
    "Example 2:\n",
    "Q1,\"{example2['Q1']}\"\n",
    "Q2,\"{example2['Q2']}\"\n",
    "Q3,\"{example2['Q3']}\"\n",
    "\n",
    "Now generate a new set of answers in the same CSV format:\n",
    "Q1,\"...\"\n",
    "Q2,\"...\"\n",
    "Q3,\"...\"\n",
    "\"\"\"\n",
    "\n",
    "# Generate synthetic data\n",
    "NUM_SYNTHETIC_SAMPLES = 5\n",
    "synthetic_rows = []\n",
    "\n",
    "for i in range(NUM_SYNTHETIC_SAMPLES):\n",
    "    print(f\"ðŸ”„ Generating sample {i+1}/{NUM_SYNTHETIC_SAMPLES}...\")\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.8,\n",
    "        )\n",
    "        content = response.choices[0].message.content\n",
    "        lines = content.strip().splitlines()\n",
    "        q1 = lines[0].split(\",\", 1)[1].strip().strip('\"')\n",
    "        q2 = lines[1].split(\",\", 1)[1].strip().strip('\"')\n",
    "        q3 = lines[2].split(\",\", 1)[1].strip().strip('\"')\n",
    "        synthetic_rows.append({\"Q1\": q1, \"Q2\": q2, \"Q3\": q3})\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    time.sleep(1.2)\n",
    "\n",
    "output_df = pd.DataFrame(synthetic_rows)\n",
    "output_df.to_csv(\"synthetic_val_data.csv\", index=True)\n",
    "print(\"Saved to synthetic_val_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa4cfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sample 1/35...\n",
      "Generating sample 2/35...\n",
      "Generating sample 3/35...\n",
      "Generating sample 4/35...\n",
      "Generating sample 5/35...\n",
      "Generating sample 6/35...\n",
      "Generating sample 7/35...\n",
      "Generating sample 8/35...\n",
      "Generating sample 9/35...\n",
      "Generating sample 10/35...\n",
      "Generating sample 11/35...\n",
      "Generating sample 12/35...\n",
      "Generating sample 13/35...\n",
      "Generating sample 14/35...\n",
      "Generating sample 15/35...\n",
      "Generating sample 16/35...\n",
      "Generating sample 17/35...\n",
      "Generating sample 18/35...\n",
      "Generating sample 19/35...\n",
      "Generating sample 20/35...\n",
      "Generating sample 21/35...\n",
      "Generating sample 22/35...\n",
      "Generating sample 23/35...\n",
      "Generating sample 24/35...\n",
      "Generating sample 25/35...\n",
      "Generating sample 26/35...\n",
      "Generating sample 27/35...\n",
      "Generating sample 28/35...\n",
      "Generating sample 29/35...\n",
      "Generating sample 30/35...\n",
      "Generating sample 31/35...\n",
      "Generating sample 32/35...\n",
      "Generating sample 33/35...\n",
      "Generating sample 34/35...\n",
      "Generating sample 35/35...\n",
      "Saved to synthetic_val_data.csv\n",
      "Token usage saved to synthetic_val_token_usage.csv\n",
      "Total time: 680.62 seconds\n",
      "Total input tokens: 47915\n",
      "Total output tokens: 13931\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import tiktoken\n",
    "from datetime import datetime\n",
    "\n",
    "client = openai.OpenAI(api_key=\"sk...\") \n",
    "enc = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "val_df = pd.read_csv(\"/Users/arashalborz/Desktop/Data/val_data.csv\")\n",
    "example1 = val_df.iloc[0]\n",
    "example2 = val_df.iloc[1]\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are generating synthetic job interview responses to the following 3 questions:\n",
    "\n",
    "Q1. Please describe a situation where you were presented with a problem outside of your comfort zone and where you were able to come up with a creative solution.\n",
    "Q2. Tell us about a time when you have failed or made a mistake. What happened? What did you learn from this experience?\n",
    "Q3. Describe a situation in which you got a group of people to work together as a team. Did you encounter any issues? What was the end result?\n",
    "\n",
    "Here are two examples of answers to these questions:\n",
    "\n",
    "Example 1:\n",
    "Q1,\"{example1['Q1']}\"\n",
    "Q2,\"{example1['Q2']}\"\n",
    "Q3,\"{example1['Q3']}\"\n",
    "\n",
    "Example 2:\n",
    "Q1,\"{example2['Q1']}\"\n",
    "Q2,\"{example2['Q2']}\"\n",
    "Q3,\"{example2['Q3']}\"\n",
    "\n",
    "Now generate a new set of answers in the same CSV format:\n",
    "Q1,\"...\"\n",
    "Q2,\"...\"\n",
    "Q3,\"...\"\n",
    "\"\"\"\n",
    "\n",
    "NUM_SYNTHETIC_SAMPLES = 35\n",
    "synthetic_rows = []\n",
    "token_stats = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(NUM_SYNTHETIC_SAMPLES):\n",
    "    print(f\"Generating sample {i+1}/{NUM_SYNTHETIC_SAMPLES}...\")\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.8,\n",
    "        )\n",
    "        content = response.choices[0].message.content\n",
    "\n",
    "        input_tokens = len(enc.encode(prompt))\n",
    "        output_tokens = len(enc.encode(content))\n",
    "        token_stats.append({\"input_tokens\": input_tokens, \"output_tokens\": output_tokens})\n",
    "\n",
    "        lines = content.strip().splitlines()\n",
    "        q1 = lines[0].split(\",\", 1)[1].strip().strip('\"')\n",
    "        q2 = lines[1].split(\",\", 1)[1].strip().strip('\"')\n",
    "        q3 = lines[2].split(\",\", 1)[1].strip().strip('\"')\n",
    "        synthetic_rows.append({\"Q1\": q1, \"Q2\": q2, \"Q3\": q3})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    time.sleep(1.2)\n",
    "\n",
    "output_df = pd.DataFrame(synthetic_rows)\n",
    "output_df.to_csv(\"synthetic_val_data.csv\", index=True)\n",
    "\n",
    "token_df = pd.DataFrame(token_stats)\n",
    "token_df.to_csv(\"synthetic_val_token_usage.csv\", index=True)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed = end_time - start_time\n",
    "total_input = sum(row[\"input_tokens\"] for row in token_stats)\n",
    "total_output = sum(row[\"output_tokens\"] for row in token_stats)\n",
    "\n",
    "print(\"Saved to synthetic_val_data.csv\")\n",
    "print(\"Token usage saved to synthetic_val_token_usage.csv\")\n",
    "print(f\"Total time: {elapsed:.2f} seconds\")\n",
    "print(f\"Total input tokens: {total_input}\")\n",
    "print(f\"Total output tokens: {total_output}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amiv_nlp_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
