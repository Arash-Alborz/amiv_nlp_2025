{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb79a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f19278a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of authors: 1568\n",
      "Labels shape: (1568, 5)\n",
      "TF-IDF features shape: (1568, 5000)\n",
      "Saved TF-IDF data to tfidf_author_data.csv ✅\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# ========== LOAD DATA ==========\n",
    "with open(\"/Users/arashalborz/Desktop/amiv_nlp_2025/Data/filtered_pandora.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# ========== PREPARE TEXTS AND LABELS ==========\n",
    "\n",
    "texts = []     # concatenated comments\n",
    "labels = []    # personality scores\n",
    "author_ids = [] # optional, in case you want to keep IDs\n",
    "\n",
    "for author in data[\"authors\"]:\n",
    "    author_id = author[\"id\"]\n",
    "    author_ids.append(author_id)\n",
    "    \n",
    "    comments = author.get(\"comments\", [])\n",
    "    # Concatenate all comments into one string\n",
    "    full_text = \" \".join(comments)\n",
    "    texts.append(full_text)\n",
    "    \n",
    "    # Get Big Five trait scores\n",
    "    trait_scores = [\n",
    "        author[\"labels\"][\"openness\"],\n",
    "        author[\"labels\"][\"conscientiousness\"],\n",
    "        author[\"labels\"][\"extraversion\"],\n",
    "        author[\"labels\"][\"agreeableness\"],\n",
    "        author[\"labels\"][\"neuroticism\"]\n",
    "    ]\n",
    "    labels.append(trait_scores)\n",
    "\n",
    "labels = np.array(labels)  # shape: (num_authors, 5)\n",
    "\n",
    "print(\"Number of authors:\", len(texts))\n",
    "print(\"Labels shape:\", labels.shape)\n",
    "\n",
    "# ========== TF-IDF VECTORIZE ==========\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # You can change max_features as needed\n",
    "\n",
    "# Fit and transform the concatenated comments\n",
    "X = vectorizer.fit_transform(texts).toarray()  # shape: (num_authors, max_features)\n",
    "\n",
    "print(\"TF-IDF features shape:\", X.shape)\n",
    "\n",
    "# ========== SAVE DATA FOR TRAINING (optional) ==========\n",
    "\n",
    "df = pd.DataFrame(X)\n",
    "df[\"openness\"] = labels[:, 0]\n",
    "df[\"conscientiousness\"] = labels[:, 1]\n",
    "df[\"extraversion\"] = labels[:, 2]\n",
    "df[\"agreeableness\"] = labels[:, 3]\n",
    "df[\"neuroticism\"] = labels[:, 4]\n",
    "df[\"author_id\"] = author_ids\n",
    "\n",
    "df.to_csv(\"tfidf_author_data.csv\", index=False)\n",
    "print(\"Saved TF-IDF data to tfidf_author_data.csv ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08746f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
       "       ...\n",
       "       '996', '997', '998', '999', 'openness', 'conscientiousness',\n",
       "       'extraversion', 'agreeableness', 'neuroticism', 'author_id'],\n",
       "      dtype='object', length=1006)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('tfidf_author_data.csv')\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "201512fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge MSE: 0.091549820669119\n",
      "Ridge R²: 0.01261319666344458\n",
      "Ridge Accuracy: 0.2878980891719745\n",
      "Ridge F1-score (macro): 0.18802014867648845\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.68      0.04      0.07       531\n",
      "         Low       0.70      0.03      0.07       615\n",
      "      Medium       0.27      0.97      0.42       424\n",
      "\n",
      "    accuracy                           0.29      1570\n",
      "   macro avg       0.55      0.35      0.19      1570\n",
      "weighted avg       0.58      0.29      0.17      1570\n",
      "\n",
      "Classification report saved to ridge_classification_report.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"tfidf_author_data.csv\")\n",
    "\n",
    "# Prepare X and Y\n",
    "X = df[[str(i) for i in range(1000)]].values\n",
    "Y = df[[\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]].values\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Ridge Regression\n",
    "model = MultiOutputRegressor(Ridge())\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Predict\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate MSE and R²\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Ridge MSE:\", mse)\n",
    "print(\"Ridge R²:\", r2)\n",
    "\n",
    "# ========== Binning Function ==========\n",
    "def score_to_label(score):\n",
    "    if score <= 32:\n",
    "        return \"Low\"\n",
    "    elif score <= 66:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"High\"\n",
    "\n",
    "def convert_scores_to_labels(array):\n",
    "    labels = []\n",
    "    for row in array:\n",
    "        row_labels = []\n",
    "        for score in row:\n",
    "            scaled_score = score * 100  # Scale 0-1 to 0-100\n",
    "            row_labels.append(score_to_label(scaled_score))\n",
    "        labels.append(row_labels)\n",
    "    return labels\n",
    "\n",
    "# Convert predictions and ground truth to labels\n",
    "pred_labels = convert_scores_to_labels(Y_pred)\n",
    "true_labels = convert_scores_to_labels(Y_test)\n",
    "\n",
    "# Flatten for F1-score and Accuracy calculation\n",
    "pred_labels_flat = [label for row in pred_labels for label in row]\n",
    "true_labels_flat = [label for row in true_labels for label in row]\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(true_labels_flat, pred_labels_flat)\n",
    "print(\"Ridge Accuracy:\", accuracy)\n",
    "\n",
    "# F1-score\n",
    "f1 = f1_score(true_labels_flat, pred_labels_flat, average=\"macro\")\n",
    "print(\"Ridge F1-score (macro):\", f1)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(true_labels_flat, pred_labels_flat)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Save report\n",
    "with open(\"ridge_classification_report.txt\", \"w\") as f:\n",
    "    f.write(\"Classification Report:\\n\")\n",
    "    f.write(report)\n",
    "\n",
    "print(\"Classification report saved to ridge_classification_report.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a294089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09047947056570406\n",
      "R²: 0.023857952405019645\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"tfidf_author_data.csv\")\n",
    "\n",
    "# Prepare X and Y\n",
    "X = df[[str(i) for i in range(1000)]].values\n",
    "Y = df[[\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]].values\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train RandomForest Regression for each trait\n",
    "model = MultiOutputRegressor(RandomForestRegressor(\n",
    "    n_estimators=100,  # number of trees\n",
    "    max_depth=None,    # you can limit this later (e.g., max_depth=10) to avoid overfitting\n",
    "    random_state=42,\n",
    "    n_jobs=-1          # use all CPU cores for speed\n",
    "))\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Predict\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R²:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65efe0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09168917339944015\n",
      "R²: 0.01074274487711806\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"tfidf_author_data.csv\")\n",
    "\n",
    "# Prepare X and Y\n",
    "X = df[[str(i) for i in range(1000)]].values\n",
    "Y = df[[\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]].values\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train XGBoost Regression for each trait\n",
    "model = MultiOutputRegressor(XGBRegressor(\n",
    "    n_estimators=100,   # number of trees\n",
    "    learning_rate=0.1,  # step size shrinkage\n",
    "    max_depth=6,        # depth of each tree\n",
    "    subsample=0.8,      # fraction of samples used per tree\n",
    "    colsample_bytree=0.8, # fraction of features per tree\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    "))\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Predict\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R²:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e1addbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest MSE: 0.09118591644108279\n",
      "RandomForest R²: 0.014977398150012066\n",
      "RandomForest Accuracy: 0.31337579617834393\n",
      "RandomForest F1-score (macro): 0.2560789869468249\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.67      0.11      0.19       531\n",
      "         Low       0.52      0.09      0.16       615\n",
      "      Medium       0.27      0.88      0.42       424\n",
      "\n",
      "    accuracy                           0.31      1570\n",
      "   macro avg       0.49      0.36      0.26      1570\n",
      "weighted avg       0.51      0.31      0.24      1570\n",
      "\n",
      "Classification report saved to randomforest_classification_report.txt ✅\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"tfidf_author_data.csv\")\n",
    "\n",
    "# Prepare X and Y\n",
    "X = df[[str(i) for i in range(1000)]].values\n",
    "Y = df[[\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]].values\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train RandomForest\n",
    "model = MultiOutputRegressor(RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    "))\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Predict\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate MSE and R²\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"RandomForest MSE:\", mse)\n",
    "print(\"RandomForest R²:\", r2)\n",
    "\n",
    "# ========== Binning Function ==========\n",
    "def score_to_label(score):\n",
    "    if score <= 32:\n",
    "        return \"Low\"\n",
    "    elif score <= 66:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"High\"\n",
    "\n",
    "def convert_scores_to_labels(array):\n",
    "    labels = []\n",
    "    for row in array:\n",
    "        row_labels = []\n",
    "        for score in row:\n",
    "            scaled_score = score * 100  # Scale 0-1 to 0-100\n",
    "            row_labels.append(score_to_label(scaled_score))\n",
    "        labels.append(row_labels)\n",
    "    return labels\n",
    "\n",
    "# Convert predictions and ground truth to labels\n",
    "pred_labels = convert_scores_to_labels(Y_pred)\n",
    "true_labels = convert_scores_to_labels(Y_test)\n",
    "\n",
    "# Flatten for F1-score and Accuracy calculation\n",
    "pred_labels_flat = [label for row in pred_labels for label in row]\n",
    "true_labels_flat = [label for row in true_labels for label in row]\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(true_labels_flat, pred_labels_flat)\n",
    "print(\"RandomForest Accuracy:\", accuracy)\n",
    "\n",
    "# F1-score\n",
    "f1 = f1_score(true_labels_flat, pred_labels_flat, average=\"macro\")\n",
    "print(\"RandomForest F1-score (macro):\", f1)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(true_labels_flat, pred_labels_flat)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Save report\n",
    "with open(\"randomforest_classification_report.txt\", \"w\") as f:\n",
    "    f.write(\"Classification Report:\\n\")\n",
    "    f.write(report)\n",
    "\n",
    "print(\"Classification report saved to randomforest_classification_report.txt ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f6e39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble MSE: 0.08838570953230483\n",
      "Ensemble R²: 0.04638519737783533\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"tfidf_author_data.csv\")\n",
    "\n",
    "# Prepare X and Y\n",
    "X = df[[str(i) for i in range(1000)]].values\n",
    "Y = df[[\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]].values\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Train Ridge ---\n",
    "ridge = MultiOutputRegressor(Ridge())\n",
    "ridge.fit(X_train, Y_train)\n",
    "ridge_pred = ridge.predict(X_test)\n",
    "\n",
    "# --- Train RandomForest ---\n",
    "rf = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))\n",
    "rf.fit(X_train, Y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "# --- Train XGBoost ---\n",
    "xgb = MultiOutputRegressor(XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=6, subsample=0.8, colsample_bytree=0.8, random_state=42, n_jobs=-1))\n",
    "xgb.fit(X_train, Y_train)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "\n",
    "# --- Combine predictions (Simple Average) ---\n",
    "final_pred = (ridge_pred + rf_pred + xgb_pred) / 3\n",
    "\n",
    "# --- Evaluate ---\n",
    "mse = mean_squared_error(Y_test, final_pred)\n",
    "r2 = r2_score(Y_test, final_pred)\n",
    "\n",
    "print(\"Ensemble MSE:\", mse)\n",
    "print(\"Ensemble R²:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3a7721a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble MSE: 0.09030300406094408\n",
      "Ensemble R²: 0.024889587856140417\n",
      "Ensemble Accuracy: 0.30636942675159234\n",
      "Ensemble F1-score (macro): 0.2380267360650983\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.68      0.09      0.16       531\n",
      "         Low       0.56      0.07      0.13       615\n",
      "      Medium       0.27      0.91      0.42       424\n",
      "\n",
      "    accuracy                           0.31      1570\n",
      "   macro avg       0.50      0.36      0.24      1570\n",
      "weighted avg       0.52      0.31      0.22      1570\n",
      "\n",
      "Classification report saved to classification_report.txt ✅\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, f1_score\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"tfidf_author_data.csv\")\n",
    "\n",
    "# Prepare X and Y\n",
    "X = df[[str(i) for i in range(1000)]].values\n",
    "Y = df[[\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]].values\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Train Ridge ---\n",
    "ridge = MultiOutputRegressor(Ridge())\n",
    "ridge.fit(X_train, Y_train)\n",
    "ridge_pred = ridge.predict(X_test)\n",
    "\n",
    "# --- Train RandomForest ---\n",
    "rf = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))\n",
    "rf.fit(X_train, Y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "# --- Train XGBoost ---\n",
    "xgb = MultiOutputRegressor(XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=6, subsample=0.8, colsample_bytree=0.8, random_state=42, n_jobs=-1))\n",
    "xgb.fit(X_train, Y_train)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "\n",
    "# --- Combine predictions (Simple Average) ---\n",
    "final_pred = (ridge_pred + rf_pred + xgb_pred) / 3\n",
    "\n",
    "# --- Evaluate MSE and R² ---\n",
    "mse = mean_squared_error(Y_test, final_pred)\n",
    "r2 = r2_score(Y_test, final_pred)\n",
    "\n",
    "print(\"Ensemble MSE:\", mse)\n",
    "print(\"Ensemble R²:\", r2)\n",
    "\n",
    "# ========== Binning Function ==========\n",
    "def score_to_label(score):\n",
    "    if score <= 32:\n",
    "        return \"Low\"\n",
    "    elif score <= 66:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"High\"\n",
    "\n",
    "# Convert continuous predictions (0-1) to 0-100, then to labels\n",
    "def convert_scores_to_labels(array):\n",
    "    labels = []\n",
    "    for row in array:\n",
    "        row_labels = []\n",
    "        for score in row:\n",
    "            scaled_score = score * 100  # Scale 0-1 to 0-100\n",
    "            row_labels.append(score_to_label(scaled_score))\n",
    "        labels.append(row_labels)\n",
    "    return labels\n",
    "\n",
    "# Convert predictions and ground truth to labels\n",
    "pred_labels = convert_scores_to_labels(final_pred)\n",
    "true_labels = convert_scores_to_labels(Y_test)\n",
    "\n",
    "# Flatten for F1-score and Accuracy calculation (optional: micro, macro, weighted)\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pred_labels_flat = [label for row in pred_labels for label in row]\n",
    "true_labels_flat = [label for row in true_labels for label in row]\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(true_labels_flat, pred_labels_flat)\n",
    "print(\"Ensemble Accuracy:\", accuracy)\n",
    "\n",
    "# F1-score\n",
    "f1 = f1_score(true_labels_flat, pred_labels_flat, average=\"macro\")\n",
    "print(\"Ensemble F1-score (macro):\", f1)\n",
    "\n",
    "report = classification_report(true_labels_flat, pred_labels_flat)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Save classification report to file\n",
    "with open(\"classification_report.txt\", \"w\") as f:\n",
    "    f.write(\"Classification Report:\\n\")\n",
    "    f.write(report)\n",
    "\n",
    "print(\"Classification report saved to classification_report.txt ✅\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amiv_nlp_2025_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
