{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ec727a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Openness\n",
      "high      837\n",
      "medium    445\n",
      "low       286\n",
      "Name: count, dtype: int64 Conscientiousness\n",
      "low       749\n",
      "medium    443\n",
      "high      376\n",
      "Name: count, dtype: int64 Extraversion\n",
      "low       823\n",
      "medium    408\n",
      "high      337\n",
      "Name: count, dtype: int64 Agreeableness\n",
      "low       716\n",
      "high      433\n",
      "medium    419\n",
      "Name: count, dtype: int64 Emotional stability\n",
      "low       598\n",
      "high      569\n",
      "medium    401\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    ">>> Checking the label distribution in train set to find bias in our Random Forest Classifier\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"/Users/arashalborz/Desktop/amiv_nlp_2025/processed_data/train/comb_train_liwc_embed.csv\")\n",
    "val_df = pd.read_csv(\"/Users/arashalborz/Desktop/amiv_nlp_2025/processed_data/validation/comb_val_liwc_embed.csv\")\n",
    "print(train_df[\"Openness\"].value_counts(), train_df[\"Conscientiousness\"].value_counts(), \n",
    "      train_df[\"Extraversion\"].value_counts(), train_df[\"Agreeableness\"].value_counts(), \n",
    "      train_df[\"Emotional stability\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f27cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Openness\n",
      "high      20\n",
      "low        8\n",
      "medium     4\n",
      "Name: count, dtype: int64 Conscientiousness\n",
      "low       20\n",
      "high       6\n",
      "medium     6\n",
      "Name: count, dtype: int64 Extraversion\n",
      "low       13\n",
      "high      10\n",
      "medium     9\n",
      "Name: count, dtype: int64 Agreeableness\n",
      "high      24\n",
      "low        5\n",
      "medium     3\n",
      "Name: count, dtype: int64 Emotional stability\n",
      "medium    15\n",
      "low       13\n",
      "high       4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    ">>> Checking the label distribution in validation set to find bias in our Random Forest Classifier\n",
    "\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"/Users/arashalborz/Desktop/amiv_nlp_2025/processed_data/train/comb_train_liwc_embed.csv\")\n",
    "val_df = pd.read_csv(\"/Users/arashalborz/Desktop/amiv_nlp_2025/processed_data/validation/comb_val_liwc_embed.csv\")\n",
    "print(val_df[\"Openness\"].value_counts(), val_df[\"Conscientiousness\"].value_counts(), \n",
    "      val_df[\"Extraversion\"].value_counts(), val_df[\"Agreeableness\"].value_counts(), \n",
    "      val_df[\"Emotional stability\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25e0cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Trait: Openness ====\n",
      "Accuracy: 0.625\n",
      "F1-score (macro): 0.4666666666666666\n",
      "\n",
      "==== Trait: Conscientiousness ====\n",
      "Accuracy: 0.625\n",
      "F1-score (macro): 0.4801587301587302\n",
      "\n",
      "==== Trait: Extraversion ====\n",
      "Accuracy: 0.46875\n",
      "F1-score (macro): 0.43994669332000663\n",
      "\n",
      "==== Trait: Agreeableness ====\n",
      "Accuracy: 0.375\n",
      "F1-score (macro): 0.36262626262626263\n",
      "\n",
      "==== Trait: Emotional stability ====\n",
      "Accuracy: 0.53125\n",
      "F1-score (macro): 0.46881091617933723\n",
      "Saved all trait-specific RF results to /Users/arashalborz/Desktop/amiv_nlp_2025/classification/reports/rf_reports/rf_per_trait_custom_params.txt\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    ">>> Script for manual experimenting with the hyperparameters for each trait classifier.\n",
    ">>> Since the label distribution for each trait is skewed, but also the dominant labels in some cases\n",
    "differ in train and test, a GridSearchCV does not help generalizing the training to job interview.\n",
    "After experimenting with GridSearchCV, we found that the best solution to build a \"fair\" classifier \n",
    "that generalizes to unseen data, is to experiment with hyperparameters manually \n",
    "and compare the results in the classification report.\n",
    ">>> There are 5 rf_classifier being trained separately for each trait. Depending on label distribution\n",
    "in train and test, there are different effects of n_estimators and max_depth for each trait classifier.\n",
    ">>> The hyperparameters in the script are the ones with highest accuracy and f1-score.\n",
    ">>> To accomplish this task, we also looked at bias in predictions. \n",
    ">>> Therefore, some hyperparameters that achieved very high accuracy and f1-score, were not uses, \n",
    "because they were biased towards dominant labels, and since the number of these had a very high percentage of \n",
    "the whole labels in the val set, the bias was evident. Hence, the best parameters are not necessarily the ones\n",
    "with highest scores, but the ones with highest scores within a \"fair\" and \"scientific\" research framework.\n",
    "\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "train_df = pd.read_csv(\"/Users/arashalborz/Desktop/amiv_nlp_2025/processed_data/train/comb_train_liwc_embed.csv\")\n",
    "val_df = pd.read_csv(\"/Users/arashalborz/Desktop/amiv_nlp_2025/processed_data/validation/comb_val_liwc_embed.csv\")\n",
    "\n",
    "feature_cols = [col for col in train_df.columns if col.startswith(\"embed_\") or col.startswith(\"liwc_\")]\n",
    "feature_cols = [col for col in feature_cols if col in val_df.columns]\n",
    "\n",
    "traits = [\"Openness\", \"Conscientiousness\", \"Extraversion\", \"Agreeableness\", \"Emotional stability\"]\n",
    "\n",
    "# trait-specific hyperparameters\n",
    "trait_params = {\n",
    "    \"Openness\": {\"n_estimators\": 14, \"max_depth\": 30},\n",
    "    \"Conscientiousness\": {\"n_estimators\": 20, \"max_depth\": None},\n",
    "    \"Extraversion\": {\"n_estimators\": 80, \"max_depth\": 30},\n",
    "    \"Agreeableness\": {\"n_estimators\": 10, \"max_depth\": 12},\n",
    "    \"Emotional stability\": {\"n_estimators\": 50, \"max_depth\": 7},\n",
    "}\n",
    "\n",
    "reports = []\n",
    "\n",
    "for trait in traits:\n",
    "    print(f\"\\n==== Trait: {trait.capitalize()} ====\")\n",
    "\n",
    "    # getting parameters for current trait (or get defaults)\n",
    "    params = trait_params.get(trait, {\"n_estimators\": 100, \"max_depth\": None})\n",
    "\n",
    "    X_train = train_df[feature_cols].values\n",
    "    y_train = train_df[trait].values\n",
    "\n",
    "    X_test = val_df[feature_cols].values\n",
    "    y_test = val_df[trait].values\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # the classifier\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=params[\"n_estimators\"],\n",
    "        max_depth=params[\"max_depth\"],\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    report = classification_report(y_test, y_pred, zero_division=0)\n",
    "\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"F1-score (macro):\", f1)\n",
    "\n",
    "    reports.append((trait, acc, f1, report))\n",
    "\n",
    "report_path = \"/Users/arashalborz/Desktop/amiv_nlp_2025/classification/reports/rf_reports/rf_per_trait_custom_params.txt\"\n",
    "with open(report_path, \"w\") as f:\n",
    "    for trait, acc, f1, rep in reports:\n",
    "        f.write(f\"=== Trait: {trait.capitalize()} ===\\n\")\n",
    "        f.write(f\"Accuracy: {acc:.4f}\\n\")\n",
    "        f.write(f\"F1-score (macro): {f1:.4f}\\n\")\n",
    "        f.write(rep + \"\\n\\n\")\n",
    "\n",
    "print(f\"Saved all trait-specific RF results to {report_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amiv_nlp_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
