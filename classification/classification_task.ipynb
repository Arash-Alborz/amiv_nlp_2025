{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4acfa565",
   "metadata": {},
   "source": [
    "## Model Comparison\n",
    "In this notebook we compared many different models for predicting personality traits. We also built voting ensembles of SVM, RF, MLP and GradientBoostingClassifier. The best result was given by random forest. We also tested SMOTE, due to strong presence of dominant labels in training set. But the result didn't show improvement, since the label distribution in validation set behaves differently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c08904a",
   "metadata": {},
   "source": [
    "### Train and validation sets:\n",
    "\n",
    "The training and validation sets used in this notebook are BERT embeddings and LIWC features concatenated in csv format.\n",
    "\n",
    "train: comb_train_liwc_embed.csv\n",
    "val_df comb_val_liwc_embed.csv\n",
    "\n",
    "Both CSV files can be found in the folder \"processes_data/\" in subfolders \"train/\" and \"validation/\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82445276",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab5bc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Trait: Openness ====\n",
      "Accuracy: 0.25\n",
      "F1-score (macro): 0.22873900293255134\n",
      "\n",
      "==== Trait: Conscientiousness ====\n",
      "Accuracy: 0.25\n",
      "F1-score (macro): 0.25250544662309365\n",
      "\n",
      "==== Trait: Extraversion ====\n",
      "Accuracy: 0.40625\n",
      "F1-score (macro): 0.2905982905982906\n",
      "\n",
      "==== Trait: Agreeableness ====\n",
      "Accuracy: 0.1875\n",
      "F1-score (macro): 0.135632183908046\n",
      "\n",
      "==== Trait: Emotional stability ====\n",
      "Accuracy: 0.375\n",
      "F1-score (macro): 0.33745654458727464\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "train_df = pd.read_csv(\"../processed_data/train/comb_train_liwc_embed.csv\")\n",
    "val_df = pd.read_csv(\"../processed_data/validation/comb_val_liwc_embed.csv\")\n",
    "\n",
    "feature_cols = [col for col in train_df.columns if col.startswith(\"embed_\") or col.startswith(\"liwc_\")]\n",
    "feature_cols = [col for col in feature_cols if col in val_df.columns] \n",
    "\n",
    "traits = [\"Openness\", \"Conscientiousness\", \"Extraversion\", \"Agreeableness\", \"Emotional stability\"]\n",
    "\n",
    "reports = []\n",
    "\n",
    "for trait in traits:\n",
    "    print(f\"\\n==== Trait: {trait.capitalize()} ====\")\n",
    "\n",
    "    X_train = train_df[feature_cols].values\n",
    "    y_train = train_df[trait].values\n",
    "\n",
    "    X_test = val_df[feature_cols].values\n",
    "    y_test = val_df[trait].values\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    svm = SVC(kernel=\"linear\", C=1.0, random_state=42)\n",
    "    svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred = svm.predict(X_test_scaled)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    report = classification_report(y_test, y_pred, zero_division=0)\n",
    "\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"F1-score (macro):\", f1)\n",
    "\n",
    "    reports.append((trait, acc, f1, report))\n",
    "\n",
    "report_path = \"reports/svm.txt\"\n",
    "with open(report_path, \"w\") as f:\n",
    "    for trait, acc, f1, rep in reports:\n",
    "        f.write(f\"=== Trait: {trait.capitalize()} ===\\n\")\n",
    "        f.write(f\"Accuracy: {acc:.4f}\\n\")\n",
    "        f.write(f\"F1-score (macro): {f1:.4f}\\n\")\n",
    "        f.write(rep + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4689fa08",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b49c5cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Trait: Openness ====\n",
      "Accuracy: 0.625\n",
      "F1-score (macro): 0.25641025641025644\n",
      "\n",
      "==== Trait: Conscientiousness ====\n",
      "Accuracy: 0.65625\n",
      "F1-score (macro): 0.44805194805194803\n",
      "\n",
      "==== Trait: Extraversion ====\n",
      "Accuracy: 0.40625\n",
      "F1-score (macro): 0.35555555555555557\n",
      "\n",
      "==== Trait: Agreeableness ====\n",
      "Accuracy: 0.1875\n",
      "F1-score (macro): 0.20915032679738563\n",
      "\n",
      "==== Trait: Emotional stability ====\n",
      "Accuracy: 0.3125\n",
      "F1-score (macro): 0.2924867724867725\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "train_df = pd.read_csv(\"../processed_data/train/comb_train_liwc_embed.csv\")\n",
    "val_df = pd.read_csv(\"../processed_data/validation/comb_val_liwc_embed.csv\")\n",
    "\n",
    "feature_cols = [col for col in train_df.columns if col.startswith(\"embed_\") or col.startswith(\"liwc_\")]\n",
    "feature_cols = [col for col in feature_cols if col in val_df.columns]\n",
    "\n",
    "traits = [\"Openness\", \"Conscientiousness\", \"Extraversion\", \"Agreeableness\", \"Emotional stability\"]\n",
    "\n",
    "reports = []\n",
    "\n",
    "for trait in traits:\n",
    "    print(f\"\\n==== Trait: {trait.capitalize()} ====\")\n",
    "\n",
    "    X_train = train_df[feature_cols].values\n",
    "    y_train = train_df[trait].values\n",
    "\n",
    "    X_test = val_df[feature_cols].values\n",
    "    y_test = val_df[trait].values\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    report = classification_report(y_test, y_pred, zero_division=0)\n",
    "\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"F1-score (macro):\", f1)\n",
    "\n",
    "    reports.append((trait, acc, f1, report))\n",
    "\n",
    "report_path = \"reports/random_forest.txt\"\n",
    "with open(report_path, \"w\") as f:\n",
    "    for trait, acc, f1, rep in reports:\n",
    "        f.write(f\"=== Trait: {trait.capitalize()} ===\\n\")\n",
    "        f.write(f\"Accuracy: {acc:.4f}\\n\")\n",
    "        f.write(f\"F1-score (macro): {f1:.4f}\\n\")\n",
    "        f.write(rep + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162ed87d",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0283fbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Gradient Boosting Script for predicting the traits separately \n",
    "based on the combined CLS-BERT-embeddings + LIWC-features\n",
    "Evaluates on validation set.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "train_df = pd.read_csv(\"../processed_data/train/comb_train_liwc_embed.csv\")\n",
    "val_df = pd.read_csv(\"../processed_data/validation/comb_val_liwc_embed.csv\")\n",
    "\n",
    "feature_cols = [col for col in train_df.columns if col.startswith(\"embed_\") or col.startswith(\"liwc_\")]\n",
    "feature_cols = [col for col in feature_cols if col in val_df.columns]  # Ensure feature overlap\n",
    "\n",
    "traits = [\"Openness\", \"Conscientiousness\", \"Extraversion\", \"Agreeableness\", \"Emotional stability\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = train_df[feature_cols].values\n",
    "X_test = val_df[feature_cols].values\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "reports = \"\"\n",
    "\n",
    "for trait in traits:\n",
    "    print(f\"\\n========== Trait: {trait} ==========\")\n",
    "\n",
    "    y_train = train_df[trait].values\n",
    "    y_test = val_df[trait].values\n",
    "\n",
    "    clf = GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=3,\n",
    "        random_state=42\n",
    "    )\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    report = classification_report(y_test, y_pred, zero_division=0)\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1-score (macro): {f1:.4f}\")\n",
    "\n",
    "    reports += f\"\\n=== Trait: {trait} ===\\n\"\n",
    "    reports += f\"Accuracy: {acc:.4f}\\n\"\n",
    "    reports += f\"F1-score (macro): {f1:.4f}\\n\"\n",
    "    reports += report + \"\\n\"\n",
    "\n",
    "output_path = \"reports/gradient_boosting.txt\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    f.write(\"Classification Reports - Gradient Boosting (Train/Val Split)\\n\")\n",
    "    f.write(reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb05154",
   "metadata": {},
   "source": [
    "## MLP classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10f587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MLP Classifier Script for predicting the traits separately \n",
    "based on the combined CLS-BERT-embeddings + LIWC-features\n",
    "Evaluates on validation set.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "train_df = pd.read_csv(\"../processed_data/train/comb_train_liwc_embed.csv\")\n",
    "val_df = pd.read_csv(\"../processed_data/validation/comb_val_liwc_embed.csv\")\n",
    "\n",
    "feature_cols = [col for col in train_df.columns if col.startswith(\"embed_\") or col.startswith(\"liwc_\")]\n",
    "feature_cols = [col for col in feature_cols if col in val_df.columns] \n",
    "\n",
    "traits = [\"Openness\", \"Conscientiousness\", \"Extraversion\", \"Agreeableness\", \"Emotional stability\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = train_df[feature_cols].values\n",
    "X_test = val_df[feature_cols].values\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "reports = \"\"\n",
    "\n",
    "for trait in traits:\n",
    "    print(f\"\\n========== Trait: {trait} ==========\")\n",
    "\n",
    "    y_train = train_df[trait].values\n",
    "    y_test = val_df[trait].values\n",
    "\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    report = classification_report(y_test, y_pred, zero_division=0)\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1-score (macro): {f1:.4f}\")\n",
    "\n",
    "    reports += f\"\\n=== Trait: {trait} ===\\n\"\n",
    "    reports += f\"Accuracy: {acc:.4f}\\n\"\n",
    "    reports += f\"F1-score (macro): {f1:.4f}\\n\"\n",
    "    reports += report + \"\\n\"\n",
    "\n",
    "output_path = \"reports/mlp.txt\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    f.write(\"Classification Reports - MLP Classifier (Train/Val Split)\\n\")\n",
    "    f.write(reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f4e0e0",
   "metadata": {},
   "source": [
    "## voting ensemble RF, GB, MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae369af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Voting Ensemble Classifier (Random Forest + Gradient Boosting + MLP)\n",
    "Train on train set and evaluate on validation set\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "train_df = pd.read_csv(\"../processed_data/train/comb_train_liwc_embed.csv\")\n",
    "val_df = pd.read_csv(\"../processed_data/validation/comb_val_liwc_embed.csv\")\n",
    "\n",
    "feature_cols = [col for col in train_df.columns if col.startswith(\"embed_\") or col.startswith(\"liwc_\")]\n",
    "feature_cols = [col for col in feature_cols if col in val_df.columns]  \n",
    "\n",
    "traits = [\"Openness\", \"Conscientiousness\", \"Extraversion\", \"Agreeableness\", \"Emotional stability\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = train_df[feature_cols].values\n",
    "X_test = val_df[feature_cols].values\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, class_weight=\"balanced\")\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)\n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[('rf', rf), ('gb', gb), ('mlp', mlp)],\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "all_reports = \"\"\n",
    "\n",
    "for trait in traits:\n",
    "    print(f\"\\n========== Predicting {trait.capitalize()} ==========\")\n",
    "\n",
    "    y_train = train_df[trait].values\n",
    "    y_test = val_df[trait].values\n",
    "\n",
    "    ensemble.fit(X_train_scaled, y_train)\n",
    "    y_pred = ensemble.predict(X_test_scaled)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    report = classification_report(y_test, y_pred, zero_division=0)\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1-score (macro): {f1:.4f}\")\n",
    "\n",
    "    all_reports += f\"\\n\\n=== {trait.upper()} ===\\n\"\n",
    "    all_reports += f\"Accuracy: {acc:.4f}\\nF1-score (macro): {f1:.4f}\\n\"\n",
    "    all_reports += report\n",
    "\n",
    "report_path = \"reports/rf_gb_mlp.txt\"\n",
    "with open(report_path, \"w\") as f:\n",
    "    f.write(\"Classification Reports - Voting Ensemble (Train/Val Split)\\n\")\n",
    "    f.write(all_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64455797",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Voting Ensemble Classifier (Random Forest + Gradient Boosting + MLP + SVM)\n",
    "Train on train set and evaluate on validation set\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "train_df = pd.read_csv(\"../processed_data/train/comb_train_liwc_embed.csv\")\n",
    "val_df = pd.read_csv(\"../processed_data/validation/comb_val_liwc_embed.csv\")\n",
    "\n",
    "feature_cols = [col for col in train_df.columns if col.startswith(\"embed_\") or col.startswith(\"liwc_\")]\n",
    "feature_cols = [col for col in feature_cols if col in val_df.columns] \n",
    "\n",
    "traits = [\"Openness\", \"Conscientiousness\", \"Extraversion\", \"Agreeableness\", \"Emotional stability\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = train_df[feature_cols].values\n",
    "X_test = val_df[feature_cols].values\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, class_weight=\"balanced\")\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)  \n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42) \n",
    "svm = SVC(kernel=\"linear\", C=1.0, probability=True, random_state=42, class_weight=\"balanced\")\n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[('rf', rf), ('gb', gb), ('mlp', mlp), ('svm', svm)],\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "all_reports = \"\"\n",
    "\n",
    "for trait in traits:\n",
    "    print(f\"\\n========== Predicting {trait.capitalize()} ==========\")\n",
    "\n",
    "    y_train = train_df[trait].values\n",
    "    y_test = val_df[trait].values\n",
    "\n",
    "    ensemble.fit(X_train_scaled, y_train)\n",
    "    y_pred = ensemble.predict(X_test_scaled)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    report = classification_report(y_test, y_pred, zero_division=0)\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1-score (macro): {f1:.4f}\")\n",
    "\n",
    "    all_reports += f\"\\n\\n=== {trait.upper()} ===\\n\"\n",
    "    all_reports += f\"Accuracy: {acc:.4f}\\nF1-score (macro): {f1:.4f}\\n\"\n",
    "    all_reports += report\n",
    "\n",
    "report_path = \"reports/rf_gb_mlp_svm.txt\"\n",
    "with open(report_path, \"w\") as f:\n",
    "    f.write(\"Classification Reports - Voting Ensemble (Train/Val Split)\\n\")\n",
    "    f.write(all_reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a328d38",
   "metadata": {},
   "source": [
    "### Ensembles with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fa1f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Voting Ensemble Classifier (Random Forest + Gradient Boosting + MLP + SVM)\n",
    "with SMOTE applied separately for each personality trait.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "train_df = pd.read_csv(\"../processed_data/train/comb_train_liwc_embed.csv\")\n",
    "val_df = pd.read_csv(\"../processed_data/validation/comb_val_liwc_embed.csv\")\n",
    "\n",
    "feature_cols = [col for col in train_df.columns if col.startswith(\"embed_\") or col.startswith(\"liwc_\")]\n",
    "feature_cols = [col for col in feature_cols if col in val_df.columns] \n",
    "\n",
    "traits = [\"Openness\", \"Conscientiousness\", \"Extraversion\", \"Agreeableness\", \"Emotional stability\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = train_df[feature_cols].values\n",
    "X_test = val_df[feature_cols].values\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, class_weight=\"balanced\")\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)\n",
    "svm = SVC(kernel=\"linear\", C=1.0, probability=True, random_state=42, class_weight=\"balanced\")\n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[('rf', rf), ('gb', gb), ('mlp', mlp), ('svm', svm)],\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "all_reports = \"\"\n",
    "\n",
    "for trait in traits:\n",
    "    print(f\"\\n========== Predicting {trait.capitalize()} ==========\")\n",
    "\n",
    "    y_train = train_df[trait].values\n",
    "    y_test = val_df[trait].values\n",
    "\n",
    "    # SMOTE \n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "    ensemble.fit(X_train_balanced, y_train_balanced)\n",
    "    y_pred = ensemble.predict(X_test_scaled)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    report = classification_report(y_test, y_pred, zero_division=0)\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1-score (macro): {f1:.4f}\")\n",
    "\n",
    "    all_reports += f\"\\n\\n=== {trait.upper()} ===\\n\"\n",
    "    all_reports += f\"Accuracy: {acc:.4f}\\nF1-score (macro): {f1:.4f}\\n\"\n",
    "    all_reports += report\n",
    "\n",
    "report_path = \"reports/voting_ensemble_all_traits_val_report.txt\"\n",
    "with open(report_path, \"w\") as f:\n",
    "    f.write(\"Classification Reports - Voting Ensemble with SMOTE (Train/Val Split)\\n\")\n",
    "    f.write(all_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122571c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Logistic Regression Script for predicting personality traits\n",
    "based on CLS-BERT embeddings + LIWC features.\n",
    "Evaluates on validation set and saves full report.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "train_df = pd.read_csv(\"../processed_data/train/comb_train_liwc_embed.csv\")\n",
    "val_df = pd.read_csv(\"../processed_data/validation/comb_val_liwc_embed.csv\")\n",
    "\n",
    "feature_cols = [col for col in train_df.columns if col.startswith(\"embed_\") or col.startswith(\"liwc_\")]\n",
    "feature_cols = [col for col in feature_cols if col in val_df.columns]\n",
    "\n",
    "traits = [\"Openness\", \"Conscientiousness\", \"Extraversion\", \"Agreeableness\", \"Emotional stability\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = train_df[feature_cols].values\n",
    "X_val = val_df[feature_cols].values\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "reports = \"\"\n",
    "\n",
    "for trait in traits:\n",
    "    print(f\"\\n========== Trait: {trait} ==========\")\n",
    "    \n",
    "    y_train = train_df[trait].values\n",
    "    y_val = val_df[trait].values\n",
    "\n",
    "    clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    y_pred = clf.predict(X_val_scaled)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred, average=\"macro\")\n",
    "    report = classification_report(y_val, y_pred, zero_division=0)\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1-score (macro): {f1:.4f}\")\n",
    "\n",
    "    reports += f\"\\n=== Trait: {trait} ===\\n\"\n",
    "    reports += f\"Accuracy: {acc:.4f}\\n\"\n",
    "    reports += f\"F1-score (macro): {f1:.4f}\\n\"\n",
    "    reports += report + \"\\n\"\n",
    "\n",
    "output_path = \"reports/logistic_regression.txt\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    f.write(\"Classification Reports - Logistic Regression (Train/Val Split)\\n\")\n",
    "    f.write(reports)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amiv_nlp_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
